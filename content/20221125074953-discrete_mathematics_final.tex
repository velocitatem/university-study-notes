% Created 2022-12-06 Tue 13:52
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\author{Daniel Rosel}
\date{\today}
\title{Discrete Mathematics - Final}
\hypersetup{
 pdfauthor={Daniel Rosel},
 pdftitle={Discrete Mathematics - Final},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.2 (Org mode 9.5.5)},
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents


\section{Domains}
\label{sec:orgad83699}
\begin{description}
\item[{Naturals \(\mathbb{N}\)}] \([1,2,3,\ldots,\infty)\)
\item[{Integers \(\mathbb{Z}\)}] \((-\infty,\ldots,-2,0,2,\ldots,\infty)\)
\item[{Rationals \(\mathbb{Q}\)}] Fractions of integers \(\{ \frac{p}{q} \vert p \in Z \land q \in Z \land q \ne 0 \}\)
\item[{Reals \(\mathbb{R}\)}] All real numbers
\item[{Complex \$\mathbb{C}}] All complex numbers
\end{description}
\section{Terminology}
\label{sec:org55ee601}
\begin{description}
\item[{Theorem}] A statement we can prove using some axioms
\item[{Proof}] A valid argument/set of arguments that demonstrate a theorem/proposition
\item[{Axioms}] Statements which are assumed to be true, they are in the most basic form
\item[{Lemma}] A small proof that is an element of another larger proof
\end{description}
\section{Propositional Logic}
\label{sec:org645862d}
A proposition, is a sentence, which can be given some \textbf{truth value}.
There are two types of propositions:
\begin{description}
\item[{Tautology}] A proposition that will always be \textbf{true} (\(\top\))
\item[{Contradiction}] A proposition that will never be true (\(\bot\))
\end{description}
\subsection{Operators}
\label{sec:org02873c8}
There are three main operators which can be used to express any logical expression. These consists of \textbf{Not, Conjunction, Disjunction}.
\subsubsection{Not}
\label{sec:org25f71ea}
It flips the truth value of a proposition.

\[
\neg p, \bar{A}
\]
\subsubsection{Conjunction}
\label{sec:orgb0c9128}
This operators returns a new truth value which is true \textbf{if both of the propositions are true}

\[
p \land q, AB
\]
\subsubsection{Disjunction}
\label{sec:orgb26a39b}
Like the conjunction, it operates on two propositions. It will return true as long as either of the propositions is true.

\[
p \lor q, A+B
\]
\subsubsection{Exclusive OR (XOR)}
\label{sec:org7b77f36}
It is very similar to the \textbf{Disjunction} except that it must be exclusively one value that is true.

\[
p \oplus q = (p \lor q) \land \neg(p \land q)
\]

\subsubsection{Conditional Statements / Implication}
\label{sec:org70f1a83}
A conditional statement consists of two parts, the \textbf{premise} and \textbf{consequence}. The truth value is \textbf{only false when \(T \to F\)}.

\[
p \to q \equiv \neg p \lor q
\]

\begin{itemize}
\item If \(p\) is True, then \(q\) must also be True, we say that p is a \textbf{sufficient condition} for \(q\). \(T \to T\)
\item If \(p\) is False, \(q\) could still be True. \(F \to T\)
\item \(p\) cannot be true if \(q\) is not true. \(F \to F\)
\item \(p\) could still be false, even if \(q\) is true. \(F \to T\)
\end{itemize}

\[
((p \to q) \land p) \to q
\]

\[
((p \to q) \land \neg q) \to \neg p
\]

\subsubsection{Bi-conditionals}
\label{sec:org7055253}
It expressed a \textbf{sufficient} and \textbf{necessary} conditional relationship between two propositions. It is read as \emph{if and only if p, then q}.

\[
p \Leftrightarrow q
\]

This operator will return True only if both p and q have equal values. The expression can be represented with the 3 basic operators as:

\[
(p \to q) \land (q \to p) \equiv (\neg p \land \neg q) \lor (p \land q)
\]

\[
p \equiv q = \neg (p \oplus q)
\]

\subsubsection{Order of Operators}
\label{sec:orgf67d995}
\begin{enumerate}
\item \(\neg\)
\item \(\land\)
\item \(\lor\)
\item \(\to\)
\item \(\Leftrightarrow\)
\end{enumerate}

\subsection{DeMorgan's Laws}
\label{sec:org284aaa4}
\begin{align}
\neg (p \land q) \equiv \neg p \lor \neg q \\
\neg (p \lor q) \equiv \neg p \land q
\end{align}

\subsection{Fallacies}
\label{sec:orgdd1777c}
The fallacies stem from the fact that an implication is true, and the truth value of either \(p,q\).
\begin{description}
\item[{Affirming the consequent}] \(((p \to q) \land q) \to p\). We falsely assume that the premise is \textbf{true} because the consequence is \textbf{true}
\item[{Nageting the antecedent}] \(((p \to q) \land \neg p) \to \neg q\). We falsely assume that the consequence is \textbf{false} because the premise is \textbf{false}.
\end{description}

\subsection{Converse, Contrapositive, Inverse}
\label{sec:org32e7bf7}
\begin{description}
\item[{Converse}] \(q \to p\)
\item[{Contrapositive}] \(\neg q \to \neg p\)
\item[{Inverse}] \(\neg p \to \neg q\)
\end{description}

The fallacies are a product of assuming that the \textbf{Converse and Inverse} are equivalent to the conditional statement.
\subsection{Disjunctive Normal Form}
\label{sec:org7b0dfc4}
This is a proposition created from the values in the truth table.

\subsection{Logical Equivalences}
\label{sec:org888a448}
These are various way you can arrive at some conclusion given a few basic propositions.
\subsubsection{Identity Laws}
\label{sec:org17e628d}
\[
p \land \top \equiv p
\]

\[
p \lor \bot \equiv p
\]
\subsubsection{Denomination Laws}
\label{sec:org8e6edb1}
\[
p \lor \top \equiv \top
\]

\[
p \land \bot \equiv \bot
\]
\subsubsection{Idempotent Laws}
\label{sec:org805a65b}
\[
p \lor p \equiv p
\]

\[
p \land p \equiv p
\]
\subsubsection{Double Negation Law}
\label{sec:org305efcf}
\[
\neg ( \neg p) \equiv p
\]
\subsubsection{Commutative Laws}
\label{sec:org3f6b4c2}
\[
p \lor q \equiv q \lor p
\]

\[
p \land q \equiv q \land p
\]
\subsubsection{Associative Laws}
\label{sec:org76a20db}
\[
(p \lor q) \lor r \equiv p \lor (q \lor r)
\]

\[
(p \land q) \land r \equiv p \land (q \land r)
\]
\subsubsection{Distributive Laws}
\label{sec:org3890aab}
\[
p \lor (q \land r) \equiv (p \lor q) \land (p \lor r)
\]

\[
p \land (q \lor r) \equiv (p \land q) \lor (p \land r)
\]
\subsubsection{\ref{sec:org284aaa4}}
\label{sec:org074dc9c}
\subsubsection{Absorption Laws}
\label{sec:org75aad49}
\[
p \lor (p \land q) \equiv p
\]

\[
p \land (p \lor q) \equiv p
\]
\subsubsection{Negation Laws}
\label{sec:org184d6cc}
\[
p \lor \neg p \equiv \top
\]

\[
p \land \neg p \equiv \bot
\]
\subsection{Satisfiability}
\label{sec:orgb17327a}
A proposition is satisfiable if it has at least one case for which it is \textbf{true}, it is anything but a \textbf{contradiction}.
\section{Predicate Logic}
\label{sec:org06f3678}
With predicate logic, we can break down a complex proposition into predicates and quantifiers.

\subsection{Predicates}
\label{sec:org2f0c7bc}
It is a statement, which is made up of a proposition, with the only difference being that it can take a parameter.

\begin{array}{l}
X \text{ is faster than me} \\
= \text{Subject} + \text{Predicate} \\
\to P(x)
\end{array}

We say that the it is instantiated once it gets evaluated with the passed parameter.

\[
P(x_1, x_2, x_3, \ldots, x_n)
\]

And once instantiated with variables:

\[
P(a_1, a_2, a_3, \ldots, a_n) \equiv p
\]

\subsection{Quantifiers}
\label{sec:org86b7d45}
With a quantifier, we can specify for which values on a certain domain, a predicate is true of false. There are various ways to express this: (\textbf{for all}, \textbf{for many}, \textbf{for at least one}, \textbf{for none}).

\subsection{Universal Quantifier}
\label{sec:org557b90d}
If we have some predicate for which we can say that all the possible values in a certain domain will make it true, we use the universal quantifier.

\begin{array}{c}
P(x) \text{ for all value of x within its domain} \\
\forall x P(x)
\end{array}

\begin{itemize}
\item To prove that this quantifier is true, we must demonstrate that it holds true for all the possible values.
\item To \textbf{dis}-prove the quantifier, it is sufficient to show that there exists just one that does not satisfy the predicate
\item If we are considering an empty set, it will always be false.
\end{itemize}

\subsection{Existential Quantifier}
\label{sec:orgb812da4}
\begin{array}{c}
P(x) \text{ for at least one value of x within its domain} \\
\exists x P(x)
\end{array}

\begin{itemize}
\item To prove this quantifier, we must find at least one value for which the predicate holds true
\item To disprove the quantifier, we must show that all the values will not hold for the predicate
\item Again, if we consider and empty set, it will always be false
\end{itemize}

\subsection{Singular Existential Quantifier}
\label{sec:org74457f2}
We can also use the existential quantifier, and with a bit of modification we can use it to specify how many values will satisfy the predict.

\begin{array}{c}
\text{There is exactly one } x \text{ such that } P(x) \\
\exists! x P(x)
\end{array}

The definition for this is as follows:

\[
\exists x (P(x) \land \forall y (P(y) \Leftrightarrow x = y))
\]

We can generalize this to a specific number \(n\) for which the predicate is satisfiable.

\[
\exists_n x P(x)
\]

\subsection{Negation}
\label{sec:org11ca087}
When negating a quantifier, we have to consider both the outside and inside, that being \textbf{the quantifier itself} and the \textbf{predicate}.

\[
\neg \forall x P(x) \equiv \exists x \neg P(x)
\]

\[
\neg \exists x P(x) \equiv \forall x \neg P(x)
\]

\subsection{Nesting}
\label{sec:org708e48a}
If we have more than one variable for which we quantify a predicate, we have to \textbf{consider the order}.

\[
\exists x \forall y P(x,y) \not \equiv \forall y \exists x P(x,y)
\]


\section{Inference}
\label{sec:org29db4fc}
A process of arriving at some conclusion through logical steps. This process consists of \textbf{arguments} which can either be valid or not. The logical form of an argument is vital, because it is the only way to determine if it is true or not.

\begin{array}{r}
p \to q \\ p
\\
\hline
\therefore q
\end{array}


It is another thing to call an argument \textbf{sound}, for this we need to have an argument for which \textbf{all premises are true and valid}. \textbf{A valid argument implies a tautology}.


\subsection{Rules of Inference}
\label{sec:orga8fd1c9}
An argument form which would generate a valid implication falls under the rules of inference
\subsubsection{Modus Ponens}
\label{sec:orgabc1068}

\begin{array}{r}
p \\
p \to q
\\
\hline
q
\end{array}


\begin{enumerate}
\item If p is true, then q is true
\item p is true
\item Therefore q is true
\end{enumerate}
\subsubsection{Modus Tollens}
\label{sec:org775239d}


\begin{array}{r}
\neg q \\
p \to q
\\
\hline
\neg p
\end{array}

\subsubsection{Hypothetical Syllogism}
\label{sec:org8888d9c}

\begin{array}{r}
p \to q \\
q \to r
\\
\hline
p \to r
\end{array}

\subsubsection{Disjunctive Syllogism}
\label{sec:org1174050}

\begin{array}{r}
p \lor q \\
\neg p
\\
\hline
q
\end{array}

\subsubsection{Addition}
\label{sec:orgc41e864}

\begin{array}{r}
p
\\
\hline
p \lor q
\end{array}

\subsubsection{Simplification}
\label{sec:org58c8e3b}

\begin{array}{r}
p \land q
\\
\hline
p
\end{array}

\subsubsection{Conjunction}
\label{sec:org26be94d}

\begin{array}{r}
p \\ q
\\
\hline
p \land q
\end{array}

\subsubsection{Resolution}
\label{sec:org5a50e6e}

\begin{array}{r}
p \lor q \\
\neg p \lor r
\\
\hline
\therefore q \lor r
\end{array}

\subsection{Rules of Inference for Quantified Propositions}
\label{sec:org43689ea}
\subsubsection{Universal Instantiation}
\label{sec:orgb1b223e}
\begin{array}{r}
\forall x P(x)
\\
\hline
\therefore P(c)
\end{array}

\subsubsection{Universal Generalization}
\label{sec:org952a7db}
\begin{array}{r}
P(c) \text{ for an arbitrary c}
\\
\hline
\therefore \forall x P(x)
\end{array}

\subsubsection{Existential Instantiation}
\label{sec:orga8da559}
\begin{array}{r}
\exists x P(x)
\\
\hline
\therefore P(c)
\end{array}

\subsubsection{Existential Generalization}
\label{sec:org8cda54e}
\begin{array}{r}
P(c) \text{ for an arbitrary c} \\
\hline
\therefore \exists x P(x)
\end{array}

\section{Formal Proofs}
\label{sec:orge536877}
This kind of proof is made up of statements which we can infer from previous statements. This we can construct using a table in which we state the logical expression and how we got to it.

\begin{align}
(p \lor q) \to (r \land s) & \quad \text{Premise} \\
r \to t & \quad \text{Premise} \\
\neg t & \quad \text{Premise} \\
\neg r & \quad \text{Modus Tollens from 2 and 3} \\
(\neg p \land \neg q) & \quad \text{Modus Tollens from 4 and 1} \\
\neg p & \quad \text{Simplification of 5}
\end{align}


\section{Informal Proofs}
\label{sec:orgec3447e}
Because a formal proof can get convoluted, we use informal proofs. The main difference here is that we don't need to provide a step-by-step description of how the proof works; we just show how the conclusion is true by describing a few intermediate steps between the theorem and the corollary. (These are called \textbf{premises} and \textbf{conclusions} in logic.)

There are various methods of proof we can use. The two primary categories for these proofs are \textbf{direct} and \textbf{indirect}.


\subsection{Methods of Proof}
\label{sec:orgd7f250d}
Upon deciding which axioms to use, you then need to use some method of proof. The most common statements we will be proving are implications.
\subsubsection{Direct Proof}
\label{sec:org744f52c}
We want to prove \textbf{"If p, then q}". This is done by assuming that the \textbf{premise} is true and then proving that the consequence is also true.

\begin{enumerate}
\item We assume \(p\) to be true.
\item By applying the laws of inference, we deduce \(q\) from \(p\).
\end{enumerate}
\subsubsection{Indirect: Proof by Contraposition}
\label{sec:orgb84564d}
If we cannot arrive to the consequence using just the premise, we can use contraposition, which states that \((p \to q) \equiv (\neg q \to \neg p)\).

\begin{enumerate}
\item We assume that \(\neg q\) is true
\item We find a way to infer that \(\neg p\) is true
\item Since this verifies the contrapositive, we have proved that \(p \to q\)
\end{enumerate}

\subsubsection{Indirect: Vacuous and Trivial proofs}
\label{sec:org7db5df7}
If we are saying that \(p \to q\) is \textbf{True}, we can assume that:
\begin{enumerate}
\item \(p\) is False (Vacuous proof)
\item \(q\) is True (Trivial proof)
\end{enumerate}

It is enough to prove just one of these (as long as we do not accept the premise being True) we can prove the condition to be True.
\begin{enumerate}
\item Example
\label{sec:orgc924fd8}
If \(n\) is an integer and an even number, then \(2n\) must be an integer.
\begin{description}
\item[{Solution}] Since an integer multiplied by another integer will also be an integer, we can say that \(q\) will be true. This is enough to prove that \(p \to q\) is also True.
\end{description}
\end{enumerate}
\subsubsection{Indirect: Proof by Contradiction}
\label{sec:org6c10e9d}
This can be used to demonstrate any statement \(p\). We say that \(\neg p\) implies a contradiction. A nicer way to think about this is by the following:

\[
\neg p \to \bot \equiv \neg (\neg p) \lor \bot \equiv p \lor \bot \equiv p
\]

If we should use proof by contradiction on an implication, we must prove that \(p \land \neg q \to \bot\). This is because in this case, we need to show that the negation of the implication is a contradiction.

\[
\neg (p \to q) \equiv \neg (\neg p \lor q) \equiv p \land \neg q \equiv \bot
\]

\begin{enumerate}
\item Example
\label{sec:org7dd3e83}
Show that \(\sqrt{2}\) is an irrational number.

\begin{description}
\item[{Solution}] An irrational number is a fraction of 2 integers. We assume that \(\sqrt{2}\) is rational. This would mean that \(\sqrt{2} = \frac{p}{q}\) where both \(p,q\) are integers. The key thing to assume here is that the fraction is in its smallest form. From the previous equation we can get to \(p^2 = 2q^2\) which tells us that \(p\) is an even number (if the square of a number even, then so is that number\$). Further, we can also come to the conclusion that \(q\) is even. Since both \(p,q\) are even, the fraction is not its simplest form - implying a contradiction.
\end{description}
\end{enumerate}
\subsubsection{Proof by Cases}
\label{sec:org65a3c1c}
This is a proof which can be used a used as a part of another proof when proving implications. If we have an implication where the premise consists of disjunctions, we can apply the following:

\begin{align}
(p_1 \lor p_2 \lor \ldots \lor p_n) \to q \\
(p_1 \to q) \land (p_2 \to q) \land \ldots \land (p_n \to q)
\end{align}

This proof is very helpful when we want to prove that a condition is satisfiable for a group of elements.

\begin{enumerate}
\item Example
\label{sec:org4042724}
Prove that if \(n\) is not a multiple of 3, \(2n\) is not a multiple of 3.
\begin{description}
\item[{Solution}] To define a value as not a multiple of 3, we have two formulas \(n = 3k + 1 \quad n = 3k + 2\). We can reformulate the proposition by saying \((n = 3k+1) \lor (n = 3k^\prime) \to \neg (2n = 3k^{\prime\prime})\). We then have to show that both cases imply the consequence.
\end{description}
\end{enumerate}
\subsubsection{Equivalence Proof}
\label{sec:orgd985d40}
As previously mentioned \(p \leftrightarrow q = p \equiv q\), so if we want to prove some equivalence, we can use \((p \to q) \land (q \to p)\).
\subsubsection{Existential Statements Proof}
\label{sec:org0da4a04}
We have two strategies for this.
\begin{description}
\item[{Constructive Proof}] We show an example that verifies a predicate and apply existential generalization to prove the proposition.
\item[{Non Constructive Proof}] We show that there exists an element which validates the predicate but we dont specify which one. This is most commonly proof by contradiction.
\end{description}
\subsubsection{Universal Statements Proof}
\label{sec:orgd06713d}
\begin{description}
\item[{Proving}] We show that a predicate holds for an arbitrary value and then apply universal generalization.
\item[{Counterexamples}] To disprove a universal statement we need to find a counterexample. This action is a process of negation, making the US an ES.
\end{description}
\subsubsection{Strategy for Proofs}
\label{sec:orgd0a2692}
So should you use? It comes down to trial and error, but also practice and intuition.
\begin{description}
\item[{Trial and error}] If direct proof doesnt work, try indirect lol.
\item[{Complex propositions}] If there are complex propositions in an implication, they quite possibly can be negated, allowing use to use an \textbf{indirect method}.
\item[{Using proof by contradiction with conditional statements}] We show that \(\neg (p \to q)\) implies \(\bot\).
\end{description}

\section{Set Theory}
\label{sec:org8aee17b}
\subsection{Sets}
\label{sec:orgcc69011}
A set is a collection of objects. We use the notation \(\{a,b,c\}\) to denote a set. We can also use the notation \(\{x \in S \mid P(x)\}\) to denote a set of elements \(x\) in \(S\) that satisfy the predicate \(P(x)\). A set can be empty, which is denoted by \(\emptyset\).

A more concrete definition of a set using quantifiers is as follows:

\[
\forall x (( x \in S) \leftrightarrow P(x))
\]

We also often use \textbf{interval definitions} to define sets. These are defined as follows:

\[
\{x \in \mathbb{R} \mid a \leq x \leq b\}
\]

A common way to define a interval is with brackets and parenthesis. For example, \((a,b)\) is an open interval, while \([a,b]\) is a closed interval.

Two sets are equal if they have the same elements. We denote this as \(A = B\). A more rigorous definition of this is as follows:

\[
A = B \equiv \forall x (x \in A \leftrightarrow x \in B)
\]

The equality of two sets can also be defined using subsets:

\[
A = B \equiv A \subseteq B \land B \subseteq A
\]

A way to disprove the equality of two sets is by showing that they have at least one element that is not in the other set. This is called a \textbf{counterexample}. It can be represented with an existential quantifier and XOR: \(\exists x (x \in A \oplus x \in B)\).

Some important elements are the aforementioned empty set \(\emptyset\) and the universal set \(\mathbb{U}\). The universal set is the set of all elements in a domain. The empty set is the set that contains no elements. The Domains, mentioned at the beginning are also sets.

\subsection{Subsets}
\label{sec:org34c89e4}
A subset is a set that is contained in another set. We denote this as \(A \subseteq B\). A more rigorous definition of this is as follows:

\[
A \subseteq B \equiv \forall x (x \in A \to x \in B)
\]

For all sets, it is true that \(A \subseteq A\) and \(\emptyset \subseteq A\). Which means that every set is a subset of itself and the empty set is a subset of every set. We can also say that \(A \subseteq B\) and \(B \subseteq A\) implies \(A = B\). This is called the \textbf{subset equality}.

What can be confusing is the proper subset. A proper subset is a subset that is not equal to the set. We denote this as \(A \subset B\). A more rigorous definition of this is as follows:

\[
A \subset B \equiv A \subseteq B \land A \neq B
\]

A quantified version of this is as follows:

\[
\forall x ((x \in A) \to (x \in B) \land (A \neq B))
\]

\subsection{Set Cardinality}
\label{sec:org327b457}
This is not the absolute value of a set. It is the number of elements in a set. We denote this as \(|A|\). A more rigorous definition of this is as follows:

\[
\vert A \vert \equiv \# \{x \in A \mid x \in A\}
\]

\subsection{Power Set}
\label{sec:orgc199818}
The power set is the set of all subsets of a set. We denote this as \(P(A)\). What is meant by all subsets is that the power set contains the empty set and the universal set aswell as all the subsets of the set. A more rigorous definition of this is as follows:

\[
P(A) \equiv \{B \mid B \subseteq A\}
\]

\textbf{The cardinality of a power set is \(2^{|A|}\).}

An example of this is the power set of \(\{1,2,3\}\) is \(\{\emptyset, \{1\}, \{2\}, \{3\}, \{1,2\}, \{1,3\}, \{2,3\}, \{1,2,3\}\}\).

What is important to remember is that the power set of a power set is the original set. This is because the power set of a set is the set of all subsets of a set. So the power set of the power set is the set of all subsets of all subsets of a set. This is the original set.

\subsection{Cartesian Product}
\label{sec:org6767bdc}
The cartesian product is the set of all ordered pairs of elements from two sets. We denote this as \(A \times B\). In other words, the cartesian product is the set of all possible combinations of elements from two sets. A more rigorous definition of this is as follows:

\[
A \times B \equiv \{(a,b) \mid a \in A \land b \in B\}
\]

\textbf{The cardinality of the cartesian product is \(|A| \times |B|\).}

An example of this is the cartesian product of \(\{1,2\}\) and \(\{3,4\}\) is \(\{(1,3), (1,4), (2,3), (2,4)\}\).

The relation of the Cartesian product to the power set is that the power set of a cartesian product is the cartesian product of the power sets. This is because the power set of a set is the set of all subsets of a set. So the power set of the cartesian product is the set of all subsets of all ordered pairs of elements from two sets. This is the cartesian product of the power sets. A mathematical proof of this is as follows:

\[
P(A \times B) = \{C \mid C \subseteq A \times B\} = \{C \mid C \subseteq \{(a,b) \mid a \in A \land b \in B\}\} = \{C \mid C \subseteq \{(a,b) \mid a \in P(A) \land b \in P(B)\}\} = P(A) \times P(B)
\]

Or simply: \(P(A \times B) = P(A) \times P(B)\).

\subsection{Set Operations}
\label{sec:orga1ad14c}
Set operations are operations that can be performed on sets. The most common set operations are union, intersection, difference, and complement.

It is important to remember that if we have an expression like \(A \subsete A \cup B\), something that could be tricky is that the order of operations is not the same as in arithmetic. In arithmetic, we would do the multiplication and division first, then addition and subtraction. In set operations, we do the complement first, then the difference, then the intersection, and finally the union. So the expression \(A \subsete A \cup B\) would be read as \(A \subsete (A \cup B)\).

Once again, \textbf{the order of operations for sets} is:
\begin{enumerate}
\item Complement
\item Difference
\item Intersection
\item Union
\end{enumerate}

\subsection{Union}
\label{sec:orga010009}
Simply explained, the union of two sets is the set of all elements that are in either set. We denote this as \(A \cup B\). A more rigorous definition of this is as follows:

\[
A \cup B \equiv \{x \mid x \in A \lor x \in B\}
\]

And using quantifiers:

\[
\forall ((x \in A \cup B) \equiv (x \in A \lor x \in B))
\]


\textbf{The cardinality of the union is \(|A| + |B| - |A \cap B|\).} The reason why we have to subtract the cardinality of the intersection is because the intersection is counted twice. Once in \(A\) and once in \(B\).

An example of this is the union of \(\{1,2\}\) and \(\{2,3\}\) is \(\{1,2,3\}\). The reason why this is the union is because \(1 \in A\), \(2 \in A\), \(2 \in B\), and \(3 \in B\). So \(1,2,3\) are all in the union.

\subsection{Intersection}
\label{sec:org8a08039}
The intersection of two sets is the set of all elements that are in both sets. We denote this as \(A \cap B\). A more rigorous definition of this is as follows:

\[
A \cap B \equiv \{x \mid x \in A \land x \in B\}
\]

\textbf{The cardinality of the intersection is \(|A \cap B|\).} What is important to remember is that the intersection of a set with itself is the set itself. This is because the intersection of a set with itself is the set of all elements that are in the set and the set itself. So the intersection of a set with itself is the set itself.

An example of this is the intersection of \(\{1,2\}\) and \(\{2,3\}\) is \(\{2\}\). The reason why this is the intersection is because \(2 \in A\) and \(2 \in B\). So \(2\) is in the intersection.

\subsection{Difference}
\label{sec:org05a9e62}
The difference of two sets is the set of all elements that are in the first set but not the second set. We denote this as \(A \setminus B\). A more rigorous definition of this is as follows:

\[
A \setminus B \equiv \{x \mid x \in A \land x \notin B\}
\]

A visual representation of this is as follows:


\begin{center}
\includegraphics[width=.9\linewidth]{Set_Theory/2022-12-06_09-56-18_Set-Difference.png}
\end{center}



The cardinality of the difference is \(|A \setminus B|\) or \(|A| - |A \cap B|\). The reason why we have to subtract the cardinality of the intersection is because the intersection is counted twice. Once in \(A\) and once in \(B\).

An example of this is the difference of \(\{1,2\}\) and \(\{2,3\}\) is \(\{1\}\). The reason why this is the difference is because \(1 \in A\) and \(1 \notin B\). So \(1\) is in the difference.

\subsection{Complement}
\label{sec:org653668c}
The complement of a set is the set of all elements that are not in the set. We denote this as \(A^c\). A more rigorous definition of this is as follows:

\[
A^c \equiv \{x \mid x \notin A\}
\]

In terms of the universal set, the complement of a set is the set of all elements that are not in the set and are in the universal set. It is denoted as \(A^c = U \setminus A\). A more rigorous definition of this is as follows:

\[
A^c \equiv \{x \mid x \in U \land x \notin A\}
\]

\textbf{The cardinality of the complement is \(|U| - |A|\).} The reason why we have to subtract the cardinality of the set is because the set is counted twice. Once in \(U\) and once in \(A\).

An example of this is the complement of \(\{1,2\}\) is \(\{3,4\}\). The reason why this is the complement is because \(3 \in U\) and \(3 \notin A\). So \(3\) is in the complement. This of course depends on the universal set being \(\{1,2,3,4\}\).

\subsection{Logical Operations with Sets}
\label{sec:org24f6600}
We can relate sets to logical operations. The most common logical operations are conjunction, disjunction, and negation. We can relate these to sets as follows:

\begin{array}{l}
A \cup B \sim p \lor q \\
A \cap B \sim p \land q \\
\bar{A} \sim \neg p
\end{array}

The reason why we can do this is that the definition of a set, is based on a predicate. So we can relate the set to the predicate and the predicate to the logical operation. For example, the definition of a set is as follows:

\[
A \equiv \{x \mid x \in A\}
\]

So we can relate the set to the predicate as follows:

\[
A \equiv \{x \mid x \in A\} \equiv \{x \mid p(x)\}
\]

\section{Functions}
\label{sec:org3d790b2}
A function, is the assignment of a single value \(b\in B\) to each element \(a\) in a set \(A\). We denote this as \(f: A \rightarrow B\). We can also call a function a mapping, transformation or a black box (in some cases even an oracle). A more rigorous definition of this is as follows:

\[
f: A \rightarrow B \equiv \{f(a) \mid a \in A\}
\]

We are mostly interested in what makes a function a function. So we will define what makes a function a function. A function is a function if the following conditions are met:
\begin{enumerate}
\item The domain of the function is a set
\item The range of the function is a set
\item The function is one-to-one
\item The function is onto
\end{enumerate}

A mathematical way to express this is as follows:

\[
\forall a \in A \exists ! b \in B \land f(a) = b
\]

The reasons why some assignments might not be functions is that not all elements in \(A\) are assigned to an element in \(B\). This is called a partial function. Another reason why some assignments might not be functions is that not all elements in \(B\) are assigned to an element in \(A\). This is called a surjection. Another reason why some assignments might not be functions is that not all elements in \(A\) are assigned to a unique element in \(B\). This is called a bijection.

How can we tell if a function is a function? We can tell if a function is a function by checking if the function is one-to-one and onto. If the function is one-to-one and onto, then the function is a function. If the function is not one-to-one and onto, then the function is not a function.

\subsection{Domain, Codomain \& Range}
\label{sec:orgbef9d61}
If \(f(a) = b\), then we call \(a\) the \textbf{pre-image} and \(b\) the \textbf{image} of \(f\). We call \(A\) the \textbf{domain} of \(f\) and \(B\) the \textbf{codomain} of \(f\). We call \(f(A)\) the \textbf{range} of \(f\).

The main difference between the \textbf{codomain} and the \textbf{range} is that the \textbf{codomain} is the set of all possible images of \(f\) and the \textbf{range} is the set of all images of \(f\).


\subsection{One-to-One}
\label{sec:org8b43906}
A function is one-to-one if each element in the range is assigned to a unique element in the domain. We denote this as \(f: A \rightarrow B\) is one-to-one. A more rigorous definition of this is as follows:

\[
f: A \rightarrow B \text{ is one-to-one } \equiv \forall a_1, a_2 \in A \land f(a_1) = f(a_2) \implies a_1 = a_2
\]

or simply: \(f(a_1) = f(a_2) \implies a_1 = a_2\).

If we want to check if a functions is one-to-one, we have to test if \(f(a_1) = f(a_2) \implies a_1 = a_2\) for all \(a_1, a_2 \in A\). If this is true for all \(a_1, a_2 \in A\), then the function is one-to-one.


\subsection{Onto}
\label{sec:org59c620f}
A function is onto if each element in the codomain is assigned to an element in the domain. We denote this as \(f: A \rightarrow B\) is onto. This is to say that for each element in the codomain, there is an element in the domain that maps to it. A more rigorous definition of this is as follows:

\[
f: A \rightarrow B \text{ is onto } \equiv \forall b \in B \exists a \in A \land f(a) = b
\]

or simply: \(\forall b \in B \exists a \in A \land f(a) = b\).

To see if a function is onto, we have to test if \(\forall b \in B \exists a \in A \land f(a) = b\). If this is true for all \(b \in B\), then the function is onto. For example if \(f: \{1,2\} \rightarrow \{1,2,3\}\), then \(f(1) = 1\), \(f(2) = 2\) and \(f(3) = 3\). So \(f\) is onto. If \(f: \{1,2\} \rightarrow \{1,2\}\), then \(f(1) = 1\), \(f(2) = 2\) and \(f(3) = 3\). So \(f\) is not onto. In this case, the function is not onto because \(3\) is not assigned to an element in the domain.

\subsection{Composite Functions}
\label{sec:org55692ae}
We can combine functions to create composite functions. We can combine functions by applying one function to the output of another function. We denote this as \(f \circ g\). We can also call this function composition. A more rigorous definition of this is as follows:

\[
f \circ g \equiv \{f(g(a)) \mid a \in A\}
\]

If the \textbf{codomain} of \(g\) is the \textbf{domain} of \(f\), then we can combine \(g\) and \(f\) to create a composite function. We denote this as \(f \circ g: A \rightarrow C\).

When it comes to functions properties after composition we have the following properties:
\begin{enumerate}
\item \(f \circ g\) is one-to-one if \(f\) is one-to-one and \(g\) is one-to-one
\item \(f \circ g\) is onto if \(f\) is onto and \(g\) is onto
\end{enumerate}

If some of the functions are not one-to-one or onto, then the composite function is not one-to-one or onto.


\subsection{Inverse Functions}
\label{sec:org7ae0507}
An inverse function is a function that undoes the effects of another function. We denote this as \(f^{-1}\). The definition is as follows:

\[
f^{-1} \equiv \{a \mid f(a) = b\}
\]

If \(f\) is one-to-one and onto, then \(f^{-1}\) is also one-to-one and onto.

\subsection{Partial Functions}
\label{sec:orga0c9333}
A partial function is a function that is not one-to-one or onto. We denote this as \(f: A \rightarrow B\) is a partial function. Definition:

\[
f: A \rightarrow B \text{ is a partial function } \equiv \exists a_1, a_2 \in A \land f(a_1) = f(a_2) \land a_1 \neq a_2
\]

or simply: \(\exists a_1, a_2 \in A \land f(a_1) = f(a_2) \land a_1 \neq a_2\). If this is true for some \(a_1, a_2 \in A\), then \(f\) is a partial function.

\subsection{Practice Questions}
\label{sec:orgb01b947}
\begin{enumerate}
\item Let \(f: \mathbb{R} \rightarrow \mathbb{R}\) be defined by \(f(x) = x^2\). Is \(f\) one-to-one? Is \(f\) onto? Is \(f\) a partial function?
\begin{description}
\item[{Solution}] \(f\) is one-to-one because \(f(x) = f(y) \implies x = y\). \(f\) is not onto because \(f(x) = x^2\) and \(x^2\) is not in the domain. \(f\) is not a partial function because \(f(x) = f(y) \implies x = y\).
\end{description}
\item Let \(f: \mathbb{R} \rightarrow \mathbb{R}\) be defined by \(f(x) = x^2\). Is \(f^{-1}\) one-to-one? Is \(f^{-1}\) onto? Is \(f^{-1}\) a partial function?
\begin{description}
\item[{Solution}] \(f^{-1}\) is one-to-one because \(f^{-1}(x) = f^{-1}(y) \implies x = y\). \(f^{-1}\) is onto because \(f^{-1}(x) = x^2\) and \(x^2\) is in the domain. \(f^{-1}\) is not a partial function because \(f^{-1}(x) = f^{-1}(y) \implies x = y\).
\end{description}
\item Let \(f: \mathbb{R} \rightarrow \mathbb{R}\) be defined by \(f(x) = x^2\). Is \(f \circ f\) one-to-one? Is \(f \circ f\) onto? Is \(f \circ f\) a partial function?
\begin{description}
\item[{Solution}] \(f \circ f\) is one-to-one because \(f\) is one-to-one and \(f\) is one-to-one. \(f \circ f\) is onto because \(f\) is onto and \(f\) is onto. \(f \circ f\) is not a partial function because \(f \circ f\) is one-to-one and \(f \circ f\) is onto.
\end{description}
\item Let \(f: \mathbb{R} \rightarrow \mathbb{R}\) be defined by \(f(x) = x^2\). Is \(f \circ f^{-1}\) one-to-one? Is \(f \circ f^{-1}\) onto? Is \(f \circ f^{-1}\) a partial function?
\begin{description}
\item[{Solution}] \(f \circ f^{-1}\) is one-to-one because \(f\) is one-to-one and \(f^{-1}\) is one-to-one. \(f \circ f^{-1}\) is onto because \(f\) is onto and \(f^{-1}\) is onto. \(f \circ f^{-1}\) is not a partial function because \(f \circ f^{-1}\) is one-to-one and \(f \circ f^{-1}\) is onto.
\end{description}
\end{enumerate}

\section{Sequences}
\label{sec:org4e5fc99}

A sequence is a set of elements, which can be continued by using intuition or mathematical patterns. We denote this as \(\{a_n \mid n \in \mathbb{N}\}\). We will mostly focus on \textbf{arithmetic} sequences and \textbf{geometric} sequences.

\subsection{Arithmetic Sequences}
\label{sec:orga5ad7d6}
An arithmetic sequence is a sequence where the difference between two consecutive terms is constant. We denote this as \(\{a_n \mid n \in \mathbb{N}\}\) where \(a_n = a_1 + (n-1)d\) for some \(a_1, d \in \mathbb{R}\). We can also write this as \(a_n = a_1 + nd\), where \(n\) is the \textbf{nth} term of the sequence and \(d\) is the \textbf{common difference}.

An arithmetic sequence is defined by the following properties:
\begin{enumerate}
\item \(a_n = a_1 + (n-1)d\)
\item \(a_n = a_1 + nd\)
\end{enumerate}

This sequence can also be thought of as a linear function. We can write this as \(a_n = f(n)\) where \(f(n) = a_1 + (n-1)d\). The main elements of a sequence are the \textbf{first term} and the \textbf{common difference}.

The expansion for the arithmetic sequence is as follows:

\begin{align}
a_1 = a_1 + 0d &= a_1 \\
a_2 = a_1 + 1d &= a_1 + d \\
a_3 = a_1 + 2d &= a_1 + 2d \\
a_4 = a_1 + 3d &= a_1 + 3d \\
\vdots &= \vdots \\
a_n = a_1 + (n-1)d &= a_1 + (n-1)d
\end{align}

\subsection{Geometric Sequences}
\label{sec:org1a4deb2}
A geometric sequence is a sequence where the ratio between two consecutive terms is constant. We denote this as \(\{a_n \mid n \in \mathbb{N}\}\) where \(a_n = a_1 r^{n-1}\) for some \(a_1, r \in \mathbb{R}\). We can also write this as \(a_n = a_1 r^n\), where \(n\) is the \textbf{nth} term of the sequence and \(r\) is the \textbf{common ratio}.

An expansion of such as sequence can look something like this:

\begin{align}
a_1 &= a_1 \\
a_2 &= a_1 r \\
a_3 &= a_1 r^2 \\
a_4 &= a_1 r^3 \\
\vdots &= \vdots \\
a_n &= a_1 r^{n-1}
\end{align}

\subsection{Recurrence Relations}
\label{sec:orge71ba80}
A recurrence relation is a sequence that is defined by a formula. We denote this as \(\{a_n \mid n \in \mathbb{N}\}\) where \(a_n = f(a_{n-1})\) for some \(f: \mathbb{R} \rightarrow \mathbb{R}\). It takes the previous term and applies a function to it to get the next term.

We can be told to find the closed formula for a sequence. This is a formula that can be used to find the nth term of a sequence.To do this, we need to use iteration and induction. We can use the following rules to find the closed formula for a sequence:
\begin{enumerate}
\item \(a_n = a_1 + (n-1)d\) where \(a_1, d \in \mathbb{R}\)
\item \(a_n = a_1 r^{n-1}\) where \(a_1, r \in \mathbb{R}\)
\item \(a_n = f(a_{n-1})\) where \(f: \mathbb{R} \rightarrow \mathbb{R}\)
\item \(a_n = f(a_{n-1}, a_{n-2})\) where \(f: \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}\)
\end{enumerate}

In short, we need to find the pattern in the sequence and use that to find the closed formula.

\section{Summations}
\label{sec:org38d7d53}
A summation is a way to add up a sequence of numbers. We denote this as \(\sum_{i=1}^n a_i\). There are many ways to define a summation. To find the sum of a sequence, we can use the following rules:
\begin{enumerate}
\item \(\sum_{i=1}^n i = \frac{n(n+1)}{2}\)
\item \(\sum_{i=1}^n i^2 = \frac{n(n+1)(2n+1)}{6}\)
\item \(\sum_{i=1}^n i^3 = \frac{n^2(n+1)^2}{4}\)
\item \(\sum_{i=1}^n C * f(i) = \frac{C}{1-r}\)
\end{enumerate}

If we subtract 1 from the upper bound, we can find the sum of the sequence. For example, \(\sum_{i=1}^n i = \sum_{i=0}^{n-1} i + n = \sum_{i=0}^{n-1} i + \sum_{i=n}^n i = \sum_{i=0}^{n-1} i + n = \frac{n(n-1)}{2} + n = \frac{n(n+1)}{2}\).

If we have nested summations, we can expand the far-right summation and include it in each iteration of the left summation.

\section{Number Theory}
\label{sec:org4a36ff2}
\section{Divisibility}
\label{sec:orgbbd958b}
A number is divisible by another number if the remainder is 0. We denote this as \(a \mid b\) where \(a\) is the divisor and \(b\) is the dividend. We can also write this as \(a = q \cdot d + r\) where \(r\) is the remainder and \(q\) is the quotient. It is important to note that \(r\) is always less than \(d\) and always positive.

The elements in the primary equation are as follows:
\begin{enumerate}
\item \(a\) is the dividend
\item \(d\) is the divisor
\item \(q\) is the quotient
\item \(r\) is the remainder
\end{enumerate}

From this equation we gain two new operations, the \textbf{division} operation and the \textbf{modulus} operation. We can use these operations to find the remainder and quotient of a division problem.

If we perform division of a negative number, we cannot have a negative remainder. To solve this, we can add the divisor to the dividend until the remainder is positive. This is called the \textbf{floor division} operation. In other words, we want to 'overshoot' with the dividend and then compensate with the remainder.

\begin{itemize}
\item Division Function: This function is onto but not one-to-one
\item Modulus Function: This function neither one-to-one or onto
\end{itemize}


\subsection{Divisibility Rules}
\label{sec:orgddf0e0b}
We can use divisibility rules to determine if a number is divisible by another number. The rules are as follows:
\begin{enumerate}
\item If \(a\) divides both \(b\) and \(c\), then \(a\) divides \(b+c\). Expression: \(a \mid b \land a \mid c \Rightarrow a \mid (b+c)\)
\item If \(a\) divides \(b\), then \(a\) divides any multiple of \(b\). Expression: \(a \mid b \implies a \mid bm\) for some \(m \in \mathbb{N}\)
\item If \(a\) divides \(b\) and \(b\) divides \(c\), then \(a\) divides \(c\). Expression: \(a \mid b \land b \mid c \Rightarrow a \mid c\)
\end{enumerate}

\section{Modular Arithmetic}
\label{sec:org1fe8803}
Modular arithmetic uses the modulus operation to find the remainder of a division problem. We use the notation \(a \equiv b \pmod{m}\) to denote that \(a\) is congruent to \(b\) modulo \(m\).

If we want to identify if two integers are congruent modulo \(m\), we can test this in the following way:
\begin{enumerate}
\item \(a \equiv b \pmod{m} \land b \equiv c \pmod{m} \Rightarrow a \equiv c \pmod{m}\)
\end{enumerate}

\textbf{In other words, if the remainder of the modulus operation is the same, then the two numbers are congruent modulo \(m\).}


\section{Integer Representation}
\label{sec:orgf50aabf}
Integers can be represented in many ways. In every day life, we use the base 10 system. This means that we use the digits 0-9 to represent numbers. We can also use the base 2 system. This means that we use the digits 0-1 to represent numbers. We can also use the base 16 system. This means that we use the digits 0-9 and A-F to represent numbers. We can also use the base 26 system. This means that we use the digits A-Z to represent numbers.

If we want to convert the value of base \(b\) to base \(b'\), we can use the following formula:

\[
n = a_k b^k + a_{k-1} b^{k-1} + \cdots + a_1 b + a_0
\]

The general algorithm for calculating the number representation is as follows:
\begin{enumerate}
\item Divide the number by the base
\item Take the remainder and add it to the list of digits
\item Repeat until the number is 0
\end{enumerate}

In mathematics:

\begin{align}
n = a_0 + bq_0 \\
n = a_1 + b(a_1 + bq_1) \\
n = a_2 + b(a_1 + b(a_2 + bq_2))
\end{align}


\section{Binary Representation}
\label{sec:org1a68b94}
Binary representation is the representation of numbers in base 2. We can use the following rules to convert from base 10 to base 2:
\begin{enumerate}
\item Divide the number by 2
\item Take the remainder and add it to the list of digits
\item Repeat until the number is 0
\end{enumerate}

To then put together the binary string we take each bit in reverse order and put it together. For example, the binary representation of 13 is 1101.

To make life a bit easier, we can use a table to convert from base 10 to base 2. The table is made up of the powers of 2 and the digits 0-1.
\begin{center}
\begin{tabular}{rrrrrrrr}
2\textsuperscript{7} & 2\textsuperscript{6} & 2\textsuperscript{5} & 2\textsuperscript{4} & 2\textsuperscript{3} & 2\textsuperscript{2} & 2\textsuperscript{1} & 2\textsuperscript{0}\\
\hline
128 & 64 & 32 & 16 & 8 & 4 & 2 & 1\\
\end{tabular}
\end{center}


\section{Hexadecimal Representation}
\label{sec:orgef4295b}
Hexadecimal representation is the representation of numbers in base 16. We can use the following rules to convert from base 10 to base 16:
\begin{enumerate}
\item Divide the number by 16
\item Take the remainder and add it to the list of digits
\item Repeat until the number is 0
\end{enumerate}

To then put together the hexadecimal string we take each digit in reverse order and put it together. For example, the hexadecimal representation of 15816 is 3DC8. The steps taken to get to this number are as follows:
\begin{enumerate}
\item 15816 / 16 = 988 remainder 8
\item 988 / 16 = 61 remainder 12 (12 is C in hexadecimal)
\item 61 / 16 = 3 remainder 13 (13 is represented as D in hexadecimal)
\item 3 / 16 = 0 remainder 3
\item 3DC8
\end{enumerate}

\section{Prime Numbers}
\label{sec:org1ba44e4}
\section{Algorithms}
\label{sec:orgde22366}
An algorithm is a collection of instructions that are made to solve a problem. To create any algorithm, we need three basic components:
\begin{description}
\item[{Sequence}] A sequence is a list of instructions that are executed in order
\item[{Selection}] A selection is a list of instructions that are executed based on a condition
\item[{Iteration}] An iteration is a list of instructions that are executed multiple times
\end{description}

\subsection{Complexity of Algorithms}
\label{sec:orgce93136}
The complexity of an algorithm is given by the relation between the input size and the number of steps required to solve the problem. We can use the following notations to describe the complexity of an algorithm:
\begin{description}
\item[{\(O(n)\)}] This notation describes the worst case scenario for an algorithm. This means that the algorithm will take at least this amount of time to solve the problem.
\item[{\(\Omega(n)\)}] This notation describes the best case scenario for an algorithm. This means that the algorithm will take at most this amount of time to solve the problem.
\item[{\(\Theta(n)\)}] This notation describes the average case scenario for an algorithm. This means that the algorithm will take this amount of time to solve the problem.
\end{description}

We will not need omega and theta notation for the exam, but it is good to know.
\subsection{Big O Notation}
\label{sec:orge64b635}
Big O notation is used to describe the worst case scenario for an algorithm. We can use the following rules to determine the complexity of an algorithm:
\begin{enumerate}
\item \(O(C)\) :: This means that the algorithm will take a constant amount of time to solve the problem. This means that the algorithm will take the same amount of time to solve the problem regardless of the input size.
\item \(O(n)\) :: This means that the algorithm will take a linear amount of time to solve the problem. This means that the algorithm will take a linear amount of time to solve the problem. This means that the algorithm will take \(n\) amount of time to solve the problem.
\item \(O(n^2)\) :: This means that the algorithm will take a quadratic amount of time to solve the problem. This means that the algorithm will take \(n^2\) amount of time to solve the problem.
\item \(O(2^n)\) :: This means that the algorithm will take an exponential amount of time to solve the problem. This means that the algorithm will take \(2^n\) amount of time to solve the problem.
\item \(O(n!)\) :: This means that the algorithm will take a factorial amount of time to solve the problem. This means that the algorithm will take \(n!\) amount of time to solve the problem.
\end{enumerate}


The idea of this notation is that we can use it to compare the complexity of different algorithms. For example, if we have two algorithms that solve the same problem, we can use big O notation to determine which algorithm is better. If one algorithm is \(O(n)\) and the other is \(O(n^2)\), then the first algorithm is better than the second algorithm.



\section{Cryptography}
\label{sec:orgd0e6d55}

\section{Relations}
\label{sec:org6790652}

\section{Computation}
\label{sec:orgf589139}
\end{document}